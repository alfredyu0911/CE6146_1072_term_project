{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from scipy import fftpack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import hann\n",
    "from scipy.signal import convolve\n",
    "from scipy import stats\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from itertools import product\n",
    "\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "\n",
    "import timeit\n",
    "import multiprocessing as mp\n",
    "\n",
    "from IPython.display import HTML\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file/folder check ../input/LANL-Earthquake-Prediction  : True\n",
      "file/folder check ../input/LANL-Earthquake-Prediction/test/  : True\n",
      "file/folder check ../input/LANL-Earthquake-Prediction/train.csv  : True\n",
      "file/folder check ../input/LANL-Earthquake-Prediction/sample_submission.csv  : True\n"
     ]
    }
   ],
   "source": [
    "def printLog(string):\n",
    "    os.system('echo ' + str(string))\n",
    "    print(string)\n",
    "\n",
    "PATH = '../input/'\n",
    "\n",
    "if os.path.isdir('../input/train.csv') == False:\n",
    "    PATH = '../input/LANL-Earthquake-Prediction'\n",
    "    \n",
    "FOLDER_PATH_TEST = os.path.join(PATH, 'test/')\n",
    "FILE_PATH_TRAIN = os.path.join(PATH, 'train.csv')\n",
    "FILE_PATH_SUBMISSION = os.path.join(PATH, 'sample_submission.csv')\n",
    "printLog('file/folder check ' + PATH + '  : ' + str(os.path.isdir(PATH)))\n",
    "printLog('file/folder check ' + FOLDER_PATH_TEST + '  : ' + str(os.path.isdir(FOLDER_PATH_TEST)))\n",
    "printLog('file/folder check ' + FILE_PATH_TRAIN + '  : ' + str(os.path.isfile(FILE_PATH_TRAIN)))\n",
    "printLog('file/folder check ' + FILE_PATH_SUBMISSION + '  : ' + str(os.path.isfile(FILE_PATH_SUBMISSION)))\n",
    "pd.options.display.precision = 20\n",
    "segment_size = 150000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing data done preparing.\n",
      "total 1056 of features are used.\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('../input/0520test/train_data_v15.csv')\n",
    "train_data.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
    "test_data = pd.read_csv('../input/0520test/test_data_v15.csv')\n",
    "test_data.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
    "printLog('testing data done preparing.')\n",
    "\n",
    "X = train_data.drop(['target', 'seg_id'], axis=1)\n",
    "X_test = test_data.drop(['target', 'seg_id'], axis=1)\n",
    "test_segs = test_data.seg_id\n",
    "y = train_data.target\n",
    "\n",
    "del train_data, test_data\n",
    "\n",
    "means_dict = {}\n",
    "for col in X.columns:\n",
    "    if X[col].isnull().any():\n",
    "        print(col)\n",
    "        mean_value = X.loc[X[col] != -np.inf, col].mean()\n",
    "        X.loc[X[col] == -np.inf, col] = mean_value\n",
    "        X[col] = X[col].fillna(mean_value)\n",
    "        means_dict[col] = mean_value\n",
    "        \n",
    "for col in X_test.columns:\n",
    "    if X_test[col].isnull().any():\n",
    "        X_test.loc[X_test[col] == -np.inf, col] = means_dict[col]\n",
    "        X_test[col] = X_test[col].fillna(means_dict[col])\n",
    "\n",
    "printLog('total ' + str(X.values[0,:].size) + ' of features are used.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianOptimization starting ...\n",
      "|   iter    |  target   | baggin... | featur... | is_unb... | lambda_l1 | max_depth | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "Fold 0, started at Fri May 31 00:29:12 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[815]\ttraining's l1: 1.82019\tvalid_1's l1: 2.14151\n",
      "Fold 1, started at Fri May 31 00:29:29 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[888]\ttraining's l1: 1.84636\tvalid_1's l1: 1.95654\n",
      "Fold 2, started at Fri May 31 00:29:48 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[609]\ttraining's l1: 1.87204\tvalid_1's l1: 2.11638\n",
      "Fold 3, started at Fri May 31 00:30:02 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[558]\ttraining's l1: 1.92204\tvalid_1's l1: 1.92286\n",
      "Fold 4, started at Fri May 31 00:30:15 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[487]\ttraining's l1: 1.91148\tvalid_1's l1: 2.0541\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 2.038   \u001b[0m | \u001b[0m 0.5809  \u001b[0m | \u001b[0m 0.7444  \u001b[0m | \u001b[0m 0.1053  \u001b[0m | \u001b[0m 8.546   \u001b[0m | \u001b[0m 70.7    \u001b[0m | \u001b[0m 179.2   \u001b[0m | \u001b[0m 207.5   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 00:30:27 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1662]\ttraining's l1: 1.80001\tvalid_1's l1: 2.14833\n",
      "Fold 1, started at Fri May 31 00:30:46 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1424]\ttraining's l1: 1.8542\tvalid_1's l1: 1.96503\n",
      "Fold 2, started at Fri May 31 00:31:03 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[740]\ttraining's l1: 1.8875\tvalid_1's l1: 2.11405\n",
      "Fold 3, started at Fri May 31 00:31:15 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[767]\ttraining's l1: 1.92474\tvalid_1's l1: 1.93663\n",
      "Fold 4, started at Fri May 31 00:31:27 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[482]\ttraining's l1: 1.93961\tvalid_1's l1: 2.05169\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 2.043   \u001b[0m | \u001b[95m 0.9035  \u001b[0m | \u001b[95m 0.5455  \u001b[0m | \u001b[95m 0.8896  \u001b[0m | \u001b[95m 24.6    \u001b[0m | \u001b[95m 82.11   \u001b[0m | \u001b[95m 177.2   \u001b[0m | \u001b[95m 166.4   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 00:31:40 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[710]\ttraining's l1: 1.88998\tvalid_1's l1: 2.1197\n",
      "Fold 1, started at Fri May 31 00:31:47 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[448]\ttraining's l1: 1.97565\tvalid_1's l1: 1.95205\n",
      "Fold 2, started at Fri May 31 00:31:52 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[333]\ttraining's l1: 1.96424\tvalid_1's l1: 2.15414\n",
      "Fold 3, started at Fri May 31 00:31:57 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[232]\ttraining's l1: 2.02605\tvalid_1's l1: 1.95135\n",
      "Fold 4, started at Fri May 31 00:32:01 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[567]\ttraining's l1: 1.92611\tvalid_1's l1: 2.06545\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 2.049   \u001b[0m | \u001b[95m 0.2     \u001b[0m | \u001b[95m 0.2     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m-1.0     \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 5.0     \u001b[0m |\n",
      "Fold 0, started at Fri May 31 00:32:14 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3087]\ttraining's l1: 1.93209\tvalid_1's l1: 2.15109\n",
      "Fold 1, started at Fri May 31 00:32:36 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2538]\ttraining's l1: 1.98033\tvalid_1's l1: 1.97606\n",
      "Fold 2, started at Fri May 31 00:32:54 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1691]\ttraining's l1: 1.96542\tvalid_1's l1: 2.12457\n",
      "Fold 3, started at Fri May 31 00:33:08 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[639]\ttraining's l1: 2.05672\tvalid_1's l1: 1.94326\n",
      "Fold 4, started at Fri May 31 00:33:15 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1848]\ttraining's l1: 1.9735\tvalid_1's l1: 2.07877\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 2.055   \u001b[0m | \u001b[95m 0.866   \u001b[0m | \u001b[95m 0.7724  \u001b[0m | \u001b[95m 0.7497  \u001b[0m | \u001b[95m 8.454   \u001b[0m | \u001b[95m 1.921   \u001b[0m | \u001b[95m 198.6   \u001b[0m | \u001b[95m 6.743   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 00:33:39 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1237]\ttraining's l1: 1.92143\tvalid_1's l1: 2.14444\n",
      "Fold 1, started at Fri May 31 00:33:45 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[931]\ttraining's l1: 1.98871\tvalid_1's l1: 1.96301\n",
      "Fold 2, started at Fri May 31 00:33:51 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[907]\ttraining's l1: 1.95425\tvalid_1's l1: 2.12911\n",
      "Fold 3, started at Fri May 31 00:33:56 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[891]\ttraining's l1: 1.99868\tvalid_1's l1: 1.93331\n",
      "Fold 4, started at Fri May 31 00:34:01 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[871]\ttraining's l1: 1.96418\tvalid_1's l1: 2.07924\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 2.05    \u001b[0m | \u001b[0m 0.2604  \u001b[0m | \u001b[0m 0.2082  \u001b[0m | \u001b[0m 0.8885  \u001b[0m | \u001b[0m 1.777   \u001b[0m | \u001b[0m 99.64   \u001b[0m | \u001b[0m 190.4   \u001b[0m | \u001b[0m 7.807   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 00:34:17 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1511]\ttraining's l1: 1.94632\tvalid_1's l1: 2.15692\n",
      "Fold 1, started at Fri May 31 00:34:26 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1598]\ttraining's l1: 1.98844\tvalid_1's l1: 1.97371\n",
      "Fold 2, started at Fri May 31 00:34:36 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1584]\ttraining's l1: 1.95487\tvalid_1's l1: 2.11996\n",
      "Fold 3, started at Fri May 31 00:34:45 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1069]\ttraining's l1: 2.01767\tvalid_1's l1: 1.92968\n",
      "Fold 4, started at Fri May 31 00:34:54 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1496]\ttraining's l1: 1.96813\tvalid_1's l1: 2.06377\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 2.049   \u001b[0m | \u001b[0m 0.4622  \u001b[0m | \u001b[0m 0.204   \u001b[0m | \u001b[0m 0.8182  \u001b[0m | \u001b[0m 26.45   \u001b[0m | \u001b[0m 7.314   \u001b[0m | \u001b[0m 197.5   \u001b[0m | \u001b[0m 8.904   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 00:35:14 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[500]\ttraining's l1: 1.91401\tvalid_1's l1: 2.14888\n",
      "Fold 1, started at Fri May 31 00:35:29 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[562]\ttraining's l1: 1.94195\tvalid_1's l1: 1.97227\n",
      "Fold 2, started at Fri May 31 00:35:47 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[600]\ttraining's l1: 1.90624\tvalid_1's l1: 2.11318\n",
      "Fold 3, started at Fri May 31 00:36:06 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[392]\ttraining's l1: 1.98155\tvalid_1's l1: 1.93268\n",
      "Fold 4, started at Fri May 31 00:36:21 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[366]\ttraining's l1: 1.95658\tvalid_1's l1: 2.05375\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 2.044   \u001b[0m | \u001b[0m 0.9645  \u001b[0m | \u001b[0m 0.9446  \u001b[0m | \u001b[0m 0.1372  \u001b[0m | \u001b[0m 3.528   \u001b[0m | \u001b[0m 5.282   \u001b[0m | \u001b[0m 190.9   \u001b[0m | \u001b[0m 5.455   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 00:36:39 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[373]\ttraining's l1: 2.02525\tvalid_1's l1: 2.19932\n",
      "Fold 1, started at Fri May 31 00:36:43 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[271]\ttraining's l1: 2.08941\tvalid_1's l1: 2.04835\n",
      "Fold 2, started at Fri May 31 00:36:47 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[286]\ttraining's l1: 2.04631\tvalid_1's l1: 2.20714\n",
      "Fold 3, started at Fri May 31 00:36:51 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[307]\ttraining's l1: 2.08984\tvalid_1's l1: 2.01205\n",
      "Fold 4, started at Fri May 31 00:36:55 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[305]\ttraining's l1: 2.05447\tvalid_1's l1: 2.12307\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 2.118   \u001b[0m | \u001b[95m 0.2     \u001b[0m | \u001b[95m 0.2     \u001b[0m | \u001b[95m 1.904e-1\u001b[0m | \u001b[95m 27.0    \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 300.0   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 00:37:04 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[987]\ttraining's l1: 1.52429\tvalid_1's l1: 2.1406\n",
      "Fold 1, started at Fri May 31 00:38:01 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[880]\ttraining's l1: 1.58243\tvalid_1's l1: 1.95432\n",
      "Fold 2, started at Fri May 31 00:38:53 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[595]\ttraining's l1: 1.66345\tvalid_1's l1: 2.13234\n",
      "Fold 3, started at Fri May 31 00:39:33 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[349]\ttraining's l1: 1.82946\tvalid_1's l1: 1.98118\n",
      "Fold 4, started at Fri May 31 00:40:01 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[487]\ttraining's l1: 1.73569\tvalid_1's l1: 2.08383\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 2.058   \u001b[0m | \u001b[0m 0.2406  \u001b[0m | \u001b[0m 0.7858  \u001b[0m | \u001b[0m 0.2884  \u001b[0m | \u001b[0m 10.44   \u001b[0m | \u001b[0m-0.6397  \u001b[0m | \u001b[0m 5.078   \u001b[0m | \u001b[0m 293.5   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 00:40:42 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's l1: 1.543\tvalid_1's l1: 2.20256\n",
      "Fold 1, started at Fri May 31 00:41:50 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[188]\ttraining's l1: 1.44961\tvalid_1's l1: 2.03373\n",
      "Fold 2, started at Fri May 31 00:43:05 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[191]\ttraining's l1: 1.41796\tvalid_1's l1: 2.1885\n",
      "Fold 3, started at Fri May 31 00:44:22 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's l1: 1.62496\tvalid_1's l1: 2.10381\n",
      "Fold 4, started at Fri May 31 00:45:27 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttraining's l1: 1.48071\tvalid_1's l1: 2.16322\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 2.138   \u001b[0m | \u001b[95m 0.3848  \u001b[0m | \u001b[95m 0.5797  \u001b[0m | \u001b[95m 0.39    \u001b[0m | \u001b[95m 0.8727  \u001b[0m | \u001b[95m 96.35   \u001b[0m | \u001b[95m 5.042   \u001b[0m | \u001b[95m 144.6   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 00:46:44 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1295]\ttraining's l1: 1.84028\tvalid_1's l1: 2.14714\n",
      "Fold 1, started at Fri May 31 00:46:57 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1589]\ttraining's l1: 1.86393\tvalid_1's l1: 1.96031\n",
      "Fold 2, started at Fri May 31 00:47:13 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[949]\ttraining's l1: 1.8742\tvalid_1's l1: 2.10814\n",
      "Fold 3, started at Fri May 31 00:47:25 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[509]\ttraining's l1: 1.96692\tvalid_1's l1: 1.92776\n",
      "Fold 4, started at Fri May 31 00:47:34 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[493]\ttraining's l1: 1.94217\tvalid_1's l1: 2.04326\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 2.037   \u001b[0m | \u001b[0m 0.8541  \u001b[0m | \u001b[0m 0.367   \u001b[0m | \u001b[0m 0.3719  \u001b[0m | \u001b[0m 26.7    \u001b[0m | \u001b[0m 96.72   \u001b[0m | \u001b[0m 5.893   \u001b[0m | \u001b[0m 7.836   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 00:47:47 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[186]\ttraining's l1: 0.945807\tvalid_1's l1: 2.19295\n",
      "Fold 1, started at Fri May 31 00:49:55 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's l1: 1.14778\tvalid_1's l1: 2.05825\n",
      "Fold 2, started at Fri May 31 00:51:41 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttraining's l1: 0.919903\tvalid_1's l1: 2.16544\n",
      "Fold 3, started at Fri May 31 00:53:48 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttraining's l1: 1.00478\tvalid_1's l1: 2.04197\n",
      "Fold 4, started at Fri May 31 00:55:54 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[162]\ttraining's l1: 1.045\tvalid_1's l1: 2.12454\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 2.117   \u001b[0m | \u001b[0m 0.9723  \u001b[0m | \u001b[0m 0.6855  \u001b[0m | \u001b[0m 0.8453  \u001b[0m | \u001b[0m 0.7417  \u001b[0m | \u001b[0m 96.32   \u001b[0m | \u001b[0m 7.044   \u001b[0m | \u001b[0m 238.4   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 00:57:56 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[915]\ttraining's l1: 1.88369\tvalid_1's l1: 2.15\n",
      "Fold 1, started at Fri May 31 00:58:09 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1789]\ttraining's l1: 1.86606\tvalid_1's l1: 1.95658\n",
      "Fold 2, started at Fri May 31 00:58:31 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[794]\ttraining's l1: 1.90472\tvalid_1's l1: 2.10926\n",
      "Fold 3, started at Fri May 31 00:58:44 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[799]\ttraining's l1: 1.948\tvalid_1's l1: 1.93491\n",
      "Fold 4, started at Fri May 31 00:58:57 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[494]\ttraining's l1: 1.94954\tvalid_1's l1: 2.05701\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 2.042   \u001b[0m | \u001b[0m 0.662   \u001b[0m | \u001b[0m 0.5904  \u001b[0m | \u001b[0m 0.1887  \u001b[0m | \u001b[0m 24.9    \u001b[0m | \u001b[0m 3.948   \u001b[0m | \u001b[0m 5.656   \u001b[0m | \u001b[0m 142.5   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 00:59:13 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1594]\ttraining's l1: 1.89205\tvalid_1's l1: 2.14701\n",
      "Fold 1, started at Fri May 31 00:59:24 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[937]\ttraining's l1: 1.97197\tvalid_1's l1: 1.9718\n",
      "Fold 2, started at Fri May 31 00:59:32 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1372]\ttraining's l1: 1.90921\tvalid_1's l1: 2.11573\n",
      "Fold 3, started at Fri May 31 00:59:41 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1137]\ttraining's l1: 1.96704\tvalid_1's l1: 1.92196\n",
      "Fold 4, started at Fri May 31 00:59:51 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1072]\ttraining's l1: 1.93798\tvalid_1's l1: 2.05765\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 2.043   \u001b[0m | \u001b[0m 0.5965  \u001b[0m | \u001b[0m 0.4383  \u001b[0m | \u001b[0m 0.3771  \u001b[0m | \u001b[0m 26.16   \u001b[0m | \u001b[0m 98.11   \u001b[0m | \u001b[0m 198.5   \u001b[0m | \u001b[0m 296.6   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:00:04 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1767]\ttraining's l1: 1.97502\tvalid_1's l1: 2.15768\n",
      "Fold 1, started at Fri May 31 01:00:15 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2698]\ttraining's l1: 1.99272\tvalid_1's l1: 1.98264\n",
      "Fold 2, started at Fri May 31 01:00:31 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1567]\ttraining's l1: 1.98991\tvalid_1's l1: 2.13126\n",
      "Fold 3, started at Fri May 31 01:00:41 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1719]\ttraining's l1: 2.02577\tvalid_1's l1: 1.94453\n",
      "Fold 4, started at Fri May 31 01:00:52 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1636]\ttraining's l1: 1.99479\tvalid_1's l1: 2.08503\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 2.06    \u001b[0m | \u001b[0m 0.2238  \u001b[0m | \u001b[0m 0.7493  \u001b[0m | \u001b[0m 0.253   \u001b[0m | \u001b[0m 17.19   \u001b[0m | \u001b[0m 0.4914  \u001b[0m | \u001b[0m 195.7   \u001b[0m | \u001b[0m 297.5   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:01:07 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[215]\ttraining's l1: 0.889679\tvalid_1's l1: 2.15865\n",
      "Fold 1, started at Fri May 31 01:02:23 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttraining's l1: 1.10225\tvalid_1's l1: 2.0354\n",
      "Fold 2, started at Fri May 31 01:03:29 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[244]\ttraining's l1: 0.792424\tvalid_1's l1: 2.188\n",
      "Fold 3, started at Fri May 31 01:04:49 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[189]\ttraining's l1: 1.0035\tvalid_1's l1: 2.0636\n",
      "Fold 4, started at Fri May 31 01:05:59 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[233]\ttraining's l1: 0.842941\tvalid_1's l1: 2.13915\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 2.117   \u001b[0m | \u001b[0m 0.7028  \u001b[0m | \u001b[0m 0.2445  \u001b[0m | \u001b[0m 0.6614  \u001b[0m | \u001b[0m 0.2524  \u001b[0m | \u001b[0m 98.68   \u001b[0m | \u001b[0m 6.46    \u001b[0m | \u001b[0m 297.5   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:07:23 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's l1: 1.58454\tvalid_1's l1: 2.19549\n",
      "Fold 1, started at Fri May 31 01:08:16 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[157]\ttraining's l1: 1.45907\tvalid_1's l1: 2.02614\n",
      "Fold 2, started at Fri May 31 01:09:16 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's l1: 1.53685\tvalid_1's l1: 2.15544\n",
      "Fold 3, started at Fri May 31 01:10:13 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's l1: 1.49883\tvalid_1's l1: 2.02695\n",
      "Fold 4, started at Fri May 31 01:11:16 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[183]\ttraining's l1: 1.38987\tvalid_1's l1: 2.11451\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 2.104   \u001b[0m | \u001b[0m 0.9672  \u001b[0m | \u001b[0m 0.623   \u001b[0m | \u001b[0m 0.5031  \u001b[0m | \u001b[0m 2.515   \u001b[0m | \u001b[0m 99.6    \u001b[0m | \u001b[0m 5.49    \u001b[0m | \u001b[0m 90.33   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:12:30 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[942]\ttraining's l1: 1.70377\tvalid_1's l1: 2.15958\n",
      "Fold 1, started at Fri May 31 01:12:45 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[942]\ttraining's l1: 1.7406\tvalid_1's l1: 1.96108\n",
      "Fold 2, started at Fri May 31 01:12:58 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[550]\ttraining's l1: 1.76461\tvalid_1's l1: 2.12245\n",
      "Fold 3, started at Fri May 31 01:13:11 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[649]\ttraining's l1: 1.78203\tvalid_1's l1: 1.96631\n",
      "Fold 4, started at Fri May 31 01:13:25 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[903]\ttraining's l1: 1.72434\tvalid_1's l1: 2.06317\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 2.055   \u001b[0m | \u001b[0m 0.8048  \u001b[0m | \u001b[0m 0.2649  \u001b[0m | \u001b[0m 0.7043  \u001b[0m | \u001b[0m 26.35   \u001b[0m | \u001b[0m 98.77   \u001b[0m | \u001b[0m 5.359   \u001b[0m | \u001b[0m 174.4   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:13:46 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[470]\ttraining's l1: 1.84292\tvalid_1's l1: 2.14949\n",
      "Fold 1, started at Fri May 31 01:14:05 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[683]\ttraining's l1: 1.82209\tvalid_1's l1: 1.96243\n",
      "Fold 2, started at Fri May 31 01:14:28 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[475]\ttraining's l1: 1.85802\tvalid_1's l1: 2.11859\n",
      "Fold 3, started at Fri May 31 01:14:46 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[404]\ttraining's l1: 1.91987\tvalid_1's l1: 1.92738\n",
      "Fold 4, started at Fri May 31 01:15:02 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[474]\ttraining's l1: 1.8666\tvalid_1's l1: 2.0516\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 2.042   \u001b[0m | \u001b[0m 0.9401  \u001b[0m | \u001b[0m 0.8201  \u001b[0m | \u001b[0m 0.1195  \u001b[0m | \u001b[0m 9.651   \u001b[0m | \u001b[0m-0.9248  \u001b[0m | \u001b[0m 199.1   \u001b[0m | \u001b[0m 124.4   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:15:26 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[836]\ttraining's l1: 1.79712\tvalid_1's l1: 2.14821\n",
      "Fold 1, started at Fri May 31 01:15:47 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[715]\ttraining's l1: 1.85703\tvalid_1's l1: 1.956\n",
      "Fold 2, started at Fri May 31 01:16:06 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[573]\ttraining's l1: 1.84648\tvalid_1's l1: 2.11039\n",
      "Fold 3, started at Fri May 31 01:16:26 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[768]\ttraining's l1: 1.87002\tvalid_1's l1: 1.94975\n",
      "Fold 4, started at Fri May 31 01:16:48 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[438]\ttraining's l1: 1.89815\tvalid_1's l1: 2.05221\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 2.043   \u001b[0m | \u001b[0m 0.9919  \u001b[0m | \u001b[0m 0.9558  \u001b[0m | \u001b[0m 0.2091  \u001b[0m | \u001b[0m 26.54   \u001b[0m | \u001b[0m 99.3    \u001b[0m | \u001b[0m 98.88   \u001b[0m | \u001b[0m 299.2   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:17:13 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[179]\ttraining's l1: 1.08147\tvalid_1's l1: 2.19995\n",
      "Fold 1, started at Fri May 31 01:19:08 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttraining's l1: 1.23698\tvalid_1's l1: 2.0809\n",
      "Fold 2, started at Fri May 31 01:20:52 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's l1: 1.25116\tvalid_1's l1: 2.18467\n",
      "Fold 3, started at Fri May 31 01:22:35 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[157]\ttraining's l1: 1.19348\tvalid_1's l1: 2.09821\n",
      "Fold 4, started at Fri May 31 01:24:22 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[159]\ttraining's l1: 1.16796\tvalid_1's l1: 2.14815\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m 2.142   \u001b[0m | \u001b[95m 0.9348  \u001b[0m | \u001b[95m 0.415   \u001b[0m | \u001b[95m 0.1594  \u001b[0m | \u001b[95m 0.1045  \u001b[0m | \u001b[95m 48.64   \u001b[0m | \u001b[95m 5.01    \u001b[0m | \u001b[95m 134.2   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:26:16 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[510]\ttraining's l1: 1.72552\tvalid_1's l1: 2.12982\n",
      "Fold 1, started at Fri May 31 01:26:38 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[716]\ttraining's l1: 1.67208\tvalid_1's l1: 1.94459\n",
      "Fold 2, started at Fri May 31 01:27:04 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[413]\ttraining's l1: 1.7794\tvalid_1's l1: 2.10499\n",
      "Fold 3, started at Fri May 31 01:27:23 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[325]\ttraining's l1: 1.85612\tvalid_1's l1: 1.9367\n",
      "Fold 4, started at Fri May 31 01:27:40 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[439]\ttraining's l1: 1.77747\tvalid_1's l1: 2.04778\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 2.033   \u001b[0m | \u001b[0m 0.2948  \u001b[0m | \u001b[0m 0.653   \u001b[0m | \u001b[0m 0.4637  \u001b[0m | \u001b[0m 0.1767  \u001b[0m | \u001b[0m 59.2    \u001b[0m | \u001b[0m 59.69   \u001b[0m | \u001b[0m 144.4   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:28:04 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[149]\ttraining's l1: 1.05289\tvalid_1's l1: 2.26622\n",
      "Fold 1, started at Fri May 31 01:33:02 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[128]\ttraining's l1: 1.17904\tvalid_1's l1: 2.10063\n",
      "Fold 2, started at Fri May 31 01:37:41 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[164]\ttraining's l1: 0.978518\tvalid_1's l1: 2.21447\n",
      "Fold 3, started at Fri May 31 01:42:52 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[143]\ttraining's l1: 1.09753\tvalid_1's l1: 2.1156\n",
      "Fold 4, started at Fri May 31 01:47:48 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[160]\ttraining's l1: 1.001\tvalid_1's l1: 2.20972\n",
      "| \u001b[95m 23      \u001b[0m | \u001b[95m 2.181   \u001b[0m | \u001b[95m 0.9159  \u001b[0m | \u001b[95m 0.9324  \u001b[0m | \u001b[95m 0.02829 \u001b[0m | \u001b[95m 0.04153 \u001b[0m | \u001b[95m 22.64   \u001b[0m | \u001b[95m 5.488   \u001b[0m | \u001b[95m 185.7   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:53:03 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2515]\ttraining's l1: 1.93185\tvalid_1's l1: 2.15316\n",
      "Fold 1, started at Fri May 31 01:53:20 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2834]\ttraining's l1: 1.96356\tvalid_1's l1: 1.96246\n",
      "Fold 2, started at Fri May 31 01:53:40 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1646]\ttraining's l1: 1.95787\tvalid_1's l1: 2.12228\n",
      "Fold 3, started at Fri May 31 01:53:52 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[715]\ttraining's l1: 2.05347\tvalid_1's l1: 1.94694\n",
      "Fold 4, started at Fri May 31 01:53:59 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1777]\ttraining's l1: 1.97189\tvalid_1's l1: 2.08273\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 2.054   \u001b[0m | \u001b[0m 0.6793  \u001b[0m | \u001b[0m 0.7275  \u001b[0m | \u001b[0m 0.5072  \u001b[0m | \u001b[0m 1.745   \u001b[0m | \u001b[0m 1.488   \u001b[0m | \u001b[0m 7.836   \u001b[0m | \u001b[0m 208.2   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:54:26 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1241]\ttraining's l1: 1.95276\tvalid_1's l1: 2.15733\n",
      "Fold 1, started at Fri May 31 01:54:35 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[923]\ttraining's l1: 2.00906\tvalid_1's l1: 1.99352\n",
      "Fold 2, started at Fri May 31 01:54:42 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[930]\ttraining's l1: 1.98662\tvalid_1's l1: 2.14105\n",
      "Fold 3, started at Fri May 31 01:54:50 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[931]\ttraining's l1: 2.0196\tvalid_1's l1: 1.9432\n",
      "Fold 4, started at Fri May 31 01:54:58 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1048]\ttraining's l1: 1.97813\tvalid_1's l1: 2.08707\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 2.064   \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 106.2   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:55:16 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[624]\ttraining's l1: 1.88857\tvalid_1's l1: 2.14927\n",
      "Fold 1, started at Fri May 31 01:55:38 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[870]\ttraining's l1: 1.87898\tvalid_1's l1: 1.96896\n",
      "Fold 2, started at Fri May 31 01:56:05 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[490]\ttraining's l1: 1.91211\tvalid_1's l1: 2.12077\n",
      "Fold 3, started at Fri May 31 01:56:22 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[268]\ttraining's l1: 2.00623\tvalid_1's l1: 1.93773\n",
      "Fold 4, started at Fri May 31 01:56:35 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[453]\ttraining's l1: 1.93245\tvalid_1's l1: 2.05773\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 2.047   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.9e-12 \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 75.55   \u001b[0m | \u001b[0m 5.0     \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:57:03 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[436]\ttraining's l1: 1.85305\tvalid_1's l1: 2.19344\n",
      "Fold 1, started at Fri May 31 01:57:19 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[454]\ttraining's l1: 1.89415\tvalid_1's l1: 1.98905\n",
      "Fold 2, started at Fri May 31 01:57:36 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[453]\ttraining's l1: 1.85367\tvalid_1's l1: 2.15499\n",
      "Fold 3, started at Fri May 31 01:57:53 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[370]\ttraining's l1: 1.91465\tvalid_1's l1: 1.98914\n",
      "Fold 4, started at Fri May 31 01:58:10 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[419]\ttraining's l1: 1.87654\tvalid_1's l1: 2.10759\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 2.087   \u001b[0m | \u001b[0m 0.3962  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 27.0    \u001b[0m | \u001b[0m 46.21   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 300.0   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 01:58:37 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[280]\ttraining's l1: 1.9336\tvalid_1's l1: 2.14831\n",
      "Fold 1, started at Fri May 31 01:58:51 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's l1: 1.89328\tvalid_1's l1: 1.96473\n",
      "Fold 2, started at Fri May 31 01:59:10 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[495]\ttraining's l1: 1.87692\tvalid_1's l1: 2.11162\n",
      "Fold 3, started at Fri May 31 01:59:28 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[248]\ttraining's l1: 1.98696\tvalid_1's l1: 1.93519\n",
      "Fold 4, started at Fri May 31 01:59:41 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[531]\ttraining's l1: 1.87123\tvalid_1's l1: 2.06303\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 2.045   \u001b[0m | \u001b[0m 0.5736  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.3049  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m |\n",
      "Fold 0, started at Fri May 31 02:00:10 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[479]\ttraining's l1: 1.50413\tvalid_1's l1: 2.14443\n",
      "Fold 1, started at Fri May 31 02:01:13 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[348]\ttraining's l1: 1.64792\tvalid_1's l1: 1.96815\n",
      "Fold 2, started at Fri May 31 02:02:02 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[257]\ttraining's l1: 1.72174\tvalid_1's l1: 2.11034\n",
      "Fold 3, started at Fri May 31 02:02:44 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[313]\ttraining's l1: 1.69126\tvalid_1's l1: 1.94961\n",
      "Fold 4, started at Fri May 31 02:03:29 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[270]\ttraining's l1: 1.71946\tvalid_1's l1: 2.0566\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 2.046   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 109.6   \u001b[0m | \u001b[0m 300.0   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 02:04:24 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[354]\ttraining's l1: 1.79987\tvalid_1's l1: 2.14289\n",
      "Fold 1, started at Fri May 31 02:04:54 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[320]\ttraining's l1: 1.86504\tvalid_1's l1: 1.97816\n",
      "Fold 2, started at Fri May 31 02:05:20 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[520]\ttraining's l1: 1.7295\tvalid_1's l1: 2.11802\n",
      "Fold 3, started at Fri May 31 02:05:57 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[250]\ttraining's l1: 1.91025\tvalid_1's l1: 1.93586\n",
      "Fold 4, started at Fri May 31 02:06:21 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[327]\ttraining's l1: 1.83899\tvalid_1's l1: 2.05274\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 2.046   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.59   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 300.0   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 02:06:58 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttraining's l1: 1.67322\tvalid_1's l1: 2.21536\n",
      "Fold 1, started at Fri May 31 02:09:11 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[159]\ttraining's l1: 1.75016\tvalid_1's l1: 2.11135\n",
      "Fold 2, started at Fri May 31 02:11:16 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[226]\ttraining's l1: 1.56073\tvalid_1's l1: 2.30567\n",
      "Fold 3, started at Fri May 31 02:13:45 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttraining's l1: 1.72808\tvalid_1's l1: 2.12804\n",
      "Fold 4, started at Fri May 31 02:15:53 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[142]\ttraining's l1: 1.7619\tvalid_1's l1: 2.19497\n",
      "| \u001b[95m 31      \u001b[0m | \u001b[95m 2.191   \u001b[0m | \u001b[95m 0.2     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 59.54   \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 190.9   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 02:18:00 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[354]\ttraining's l1: 1.79987\tvalid_1's l1: 2.14289\n",
      "Fold 1, started at Fri May 31 02:18:30 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[320]\ttraining's l1: 1.86504\tvalid_1's l1: 1.97816\n",
      "Fold 2, started at Fri May 31 02:18:55 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[520]\ttraining's l1: 1.7295\tvalid_1's l1: 2.11802\n",
      "Fold 3, started at Fri May 31 02:19:32 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[250]\ttraining's l1: 1.91025\tvalid_1's l1: 1.93586\n",
      "Fold 4, started at Fri May 31 02:19:57 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[327]\ttraining's l1: 1.83899\tvalid_1's l1: 2.05274\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 2.046   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 6.441e-1\u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 218.4   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 02:20:31 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[409]\ttraining's l1: 2.07415\tvalid_1's l1: 2.2126\n",
      "Fold 1, started at Fri May 31 02:20:35 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[271]\ttraining's l1: 2.14991\tvalid_1's l1: 2.08527\n",
      "Fold 2, started at Fri May 31 02:20:39 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l1: 2.06774\tvalid_1's l1: 2.18945\n",
      "Fold 3, started at Fri May 31 02:20:44 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[385]\ttraining's l1: 2.13291\tvalid_1's l1: 1.99805\n",
      "Fold 4, started at Fri May 31 02:20:48 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[408]\ttraining's l1: 2.08827\tvalid_1's l1: 2.13195\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 2.123   \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 27.0    \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 137.6   \u001b[0m | \u001b[0m 54.61   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 02:21:02 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1674]\ttraining's l1: 1.85632\tvalid_1's l1: 2.15209\n",
      "Fold 1, started at Fri May 31 02:21:20 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1742]\ttraining's l1: 1.89417\tvalid_1's l1: 1.9636\n",
      "Fold 2, started at Fri May 31 02:21:38 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[845]\ttraining's l1: 1.92083\tvalid_1's l1: 2.11821\n",
      "Fold 3, started at Fri May 31 02:21:50 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1043]\ttraining's l1: 1.94483\tvalid_1's l1: 1.92466\n",
      "Fold 4, started at Fri May 31 02:22:04 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[852]\ttraining's l1: 1.93277\tvalid_1's l1: 2.05762\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 2.043   \u001b[0m | \u001b[0m 0.67    \u001b[0m | \u001b[0m 0.7948  \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 26.49   \u001b[0m | \u001b[0m 98.4    \u001b[0m | \u001b[0m 199.3   \u001b[0m | \u001b[0m 44.21   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 02:22:25 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[390]\ttraining's l1: 1.80331\tvalid_1's l1: 2.13557\n",
      "Fold 1, started at Fri May 31 02:22:49 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[827]\ttraining's l1: 1.6601\tvalid_1's l1: 1.95316\n",
      "Fold 2, started at Fri May 31 02:23:28 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[424]\ttraining's l1: 1.80224\tvalid_1's l1: 2.11926\n",
      "Fold 3, started at Fri May 31 02:23:54 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[350]\ttraining's l1: 1.86824\tvalid_1's l1: 1.9309\n",
      "Fold 4, started at Fri May 31 02:24:15 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[311]\ttraining's l1: 1.86213\tvalid_1's l1: 2.05614\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 2.039   \u001b[0m | \u001b[0m 0.5814  \u001b[0m | \u001b[0m 0.9874  \u001b[0m | \u001b[0m 0.8965  \u001b[0m | \u001b[0m 0.2676  \u001b[0m | \u001b[0m 98.86   \u001b[0m | \u001b[0m 133.7   \u001b[0m | \u001b[0m 106.3   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 02:24:45 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[384]\ttraining's l1: 2.03657\tvalid_1's l1: 2.18751\n",
      "Fold 1, started at Fri May 31 02:24:49 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[414]\ttraining's l1: 2.07348\tvalid_1's l1: 2.01683\n",
      "Fold 2, started at Fri May 31 02:24:54 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[513]\ttraining's l1: 2.02234\tvalid_1's l1: 2.16333\n",
      "Fold 3, started at Fri May 31 02:25:00 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[415]\ttraining's l1: 2.08293\tvalid_1's l1: 1.96569\n",
      "Fold 4, started at Fri May 31 02:25:05 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[441]\ttraining's l1: 2.04594\tvalid_1's l1: 2.0966\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 2.086   \u001b[0m | \u001b[0m 0.2447  \u001b[0m | \u001b[0m 0.681   \u001b[0m | \u001b[0m 0.6466  \u001b[0m | \u001b[0m 27.0    \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 85.69   \u001b[0m | \u001b[0m 6.055   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 02:25:17 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[818]\ttraining's l1: 1.75896\tvalid_1's l1: 2.13596\n",
      "Fold 1, started at Fri May 31 02:25:25 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[907]\ttraining's l1: 1.7738\tvalid_1's l1: 1.94786\n",
      "Fold 2, started at Fri May 31 02:25:35 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[514]\ttraining's l1: 1.85216\tvalid_1's l1: 2.11525\n",
      "Fold 3, started at Fri May 31 02:25:41 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[393]\ttraining's l1: 1.93028\tvalid_1's l1: 1.93183\n",
      "Fold 4, started at Fri May 31 02:25:47 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[462]\ttraining's l1: 1.87692\tvalid_1's l1: 2.06185\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 2.039   \u001b[0m | \u001b[0m 0.698   \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 207.5   \u001b[0m |\n",
      "Fold 0, started at Fri May 31 02:25:59 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1436]\ttraining's l1: 1.9008\tvalid_1's l1: 2.14979\n",
      "Fold 1, started at Fri May 31 02:26:16 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[800]\ttraining's l1: 1.98185\tvalid_1's l1: 1.97771\n",
      "Fold 2, started at Fri May 31 02:26:28 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1405]\ttraining's l1: 1.91021\tvalid_1's l1: 2.1172\n",
      "Fold 3, started at Fri May 31 02:26:45 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[933]\ttraining's l1: 1.9793\tvalid_1's l1: 1.93197\n",
      "Fold 4, started at Fri May 31 02:26:57 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[866]\ttraining's l1: 1.95558\tvalid_1's l1: 2.06097\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 2.048   \u001b[0m | \u001b[0m 0.4794  \u001b[0m | \u001b[0m 0.7765  \u001b[0m | \u001b[0m 0.9666  \u001b[0m | \u001b[0m 26.72   \u001b[0m | \u001b[0m 97.25   \u001b[0m | \u001b[0m 143.6   \u001b[0m | \u001b[0m 8.822   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def LGB_CV(max_depth, num_leaves, min_data_in_leaf, feature_fraction, bagging_fraction, lambda_l1, is_unbalance):\n",
    "#     folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    oof = np.zeros(len(X))\n",
    "    scores = []\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        printLog('Fold '+ str(fold_n) + ', started at '+ time.ctime())\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[train_index], X[valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "        param = {'num_leaves': int(num_leaves),\n",
    "                 'min_data_in_leaf': int(min_data_in_leaf), \n",
    "                 'objective':'gamma',\n",
    "                 'max_depth': int(max_depth),\n",
    "                 'learning_rate': 0.01,\n",
    "                 \"boosting\": \"gbdt\",\n",
    "                 \"feature_fraction\": feature_fraction,\n",
    "                 \"bagging_freq\": 1,\n",
    "                 \"bagging_fraction\": bagging_fraction ,\n",
    "                 \"bagging_seed\": 11,\n",
    "                 \"metric\": 'mae',\n",
    "                 \"lambda_l1\": lambda_l1,\n",
    "                 \"verbosity\": -1,\n",
    "                 'is_unbalance': bool(is_unbalance >= 0.5)\n",
    "                }\n",
    "        \n",
    "        model = lgb.LGBMRegressor(**param, n_estimators=50000, n_jobs = -1)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='mae', verbose=-1, early_stopping_rounds=200)\n",
    "\n",
    "        y_pred_valid = model.predict(X_valid)\n",
    "        y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(mean_absolute_error(y_valid, y_pred_valid))\n",
    "        score = np.mean(scores)\n",
    "        \n",
    "    return score\n",
    "\n",
    "#     for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, Y_train)):\n",
    "#         print(\"fold n{}\".format(fold_))\n",
    "#         trn_data = lgb.Dataset(X_train[trn_idx], label=Y_train[trn_idx])\n",
    "#         val_data = lgb.Dataset(X_train[val_id], label=Y_train[val_idx])\n",
    "    \n",
    "#         param = {'num_leaves': int(num_leaves),\n",
    "#                  'min_data_in_leaf': int(min_data_in_leaf), \n",
    "#                  'objective':'regression',\n",
    "#                  'max_depth': int(max_depth),\n",
    "#                  'learning_rate': 0.01,\n",
    "#                  \"boosting\": \"gbdt\",\n",
    "#                  \"feature_fraction\": feature_fraction,\n",
    "#                  \"bagging_freq\": 1,\n",
    "#                  \"bagging_fraction\": bagging_fraction ,\n",
    "#                  \"bagging_seed\": 11,\n",
    "#                  \"metric\": 'mae',\n",
    "#                  \"lambda_l1\": lambda_l1,\n",
    "#                  \"verbosity\": -1\n",
    "#                 }\n",
    "    \n",
    "#         clf = lgb.train(param, trn_data, 5000, valid_sets = [trn_data, val_data], verbose_eval=500001, early_stopping_rounds=500)\n",
    "        \n",
    "#         oof[val_idx] = clf.predict(X_train[val_idx], num_iteration=clf.best_iteration)\n",
    "        \n",
    "#         del clf, trn_idx, val_idx\n",
    "        \n",
    "#     return metrics.r2_score(oof, Y_train)\n",
    "\n",
    "printLog('BayesianOptimization starting ...')\n",
    "\n",
    "LGB_BO = BayesianOptimization(LGB_CV, {\n",
    "    'max_depth': (-1, 100),\n",
    "    'num_leaves': (5, 300),\n",
    "    'min_data_in_leaf': (5, 200),\n",
    "    'feature_fraction': (0.2, 1.0),\n",
    "    'bagging_fraction': (0.2, 1.0),\n",
    "    'lambda_l1': (0, 27),\n",
    "    'is_unbalance': (0, 1)\n",
    "    })\n",
    "\n",
    "LGB_BO.maximize(init_points=2, n_iter=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " score      bagging_fraction         feature_fraction           is_unbalance              lambda_l1                max_depth             min_data_in_leaf            num_leaves       \n",
      "2.03828   0.58086936437085423535   0.74442790399391456369   0.10531407426330630095   8.54574772276745342481  70.70400504168678423866 179.18043157943583310043 207.51382441248193799765\n",
      "2.04317   0.90351576601473371220   0.54545978800396777153   0.88959837658401785809  24.60295220415360617494  82.10588870462549948570 177.24651627047239799140 166.39136810322483484015\n",
      "2.04854   0.20000000000000001110   0.20000000000000001110   0.00000000000000000000   0.00000000000000000000  -1.00000000000000000000   5.00000000000000000000   5.00000000000000000000\n",
      "2.05475   0.86604058114301873950   0.77240844609726022618   0.74968302957642452000   8.45424590360210359563   1.92119511694320399542 198.63510401184532838670   6.74271162798787937476\n",
      "2.04982   0.26041248561036722808   0.20815882539179630939   0.88854869086583820881   1.77730104431241642260  99.64292867818484467080 190.39458713884559415419   7.80681832982485168770\n",
      "2.04909   0.46220505546242940387   0.20401767204376161646   0.81815270401702944181  26.44986810525250575665   7.31409078061290784945 197.54099650155475842439   8.90428932880439738540\n",
      "2.04415   0.96451815448026301247   0.94457111471178167861   0.13717766977184153721   3.52798655929705429202   5.28230519456839964221 190.86302442357839481701   5.45451192002211726617\n",
      "2.11799   0.20000000027605413511   0.20000000027605413511   0.00000000019041994764  27.00000000000000000000  99.99999999983967313710   5.00000000178342407509 300.00000000000000000000\n",
      "2.05845   0.24063871181988255588   0.78580385815950437589   0.28841954102104327973  10.43696112603936398955  -0.63974490177806853097   5.07828802391276301620 293.50112503965618770962\n",
      "2.13837   0.38482028122945033388   0.57966864616578128722   0.38997249362357611080   0.87271869644849320302  96.35082113076613552494   5.04179986926200207620 144.62212387667983648498\n",
      "2.03737   0.85406417401763223829   0.36698354592372084415   0.37188121113319350108  26.69716791396924548962  96.72257985832273163851   5.89266186146543446966   7.83598232480854317572\n",
      "2.11663   0.97233424525693834539   0.68552403643299930636   0.84526019552585196504   0.74170819197593851335  96.32343188225982544282   7.04382481004472360553 238.36396059109222278494\n",
      "2.04155   0.66195180034070144615   0.59037200710944581772   0.18871793786637214296  24.90413057943425911844   3.94756652760672821501   5.65646726594989424086 142.45924914055984800143\n",
      "2.04286   0.59649507897389830724   0.43829762450336934299   0.37710227056754064279  26.15773974215078112593  98.10516930742376473518 198.49027010616421762279 296.58061548192637246757\n",
      "2.06023   0.22377009393485344790   0.74928662069668106049   0.25304473459395737667  17.19447280813184164572   0.49138266625842375035 195.68539385584389833639 297.46235138272356834932\n",
      "2.11696   0.70281975277916974854   0.24453265381637143139   0.66141943316084517157   0.25243292942062811601  98.67824123547590886574   6.46034565522042214525 297.47678976361731884026\n",
      "2.10371   0.96722671715178676344   0.62297480385505032974   0.50314289964097524965   2.51530269218777702278  99.60255402477811514927   5.49009483253391472601  90.33295958069693654124\n",
      "2.05461   0.80483383662185659091   0.26491140331411061615   0.70431870995292344961  26.35178963990597722500  98.76815740630878792672   5.35876038644282637335 174.38035438360773810018\n",
      "2.04190   0.94011798711544947160   0.82014929568783556668   0.11946915774600219695   9.65111439193390729940  -0.92476225678569856647 199.11056187462099842378 124.38674286272424751587\n",
      "2.04331   0.99191726931503043652   0.95583874505887211903   0.20911128838517234474  26.53710271563552680618  99.30167725984358639835  98.87777667150841409693 299.19684449578215890142\n",
      "2.14238   0.93481555803785920666   0.41500693021863654941   0.15941830017986380330   0.10445588562056873361  48.64475795145006742359   5.01009856532327191303 134.15132894725545043002\n",
      "2.03278   0.29484511452849737623   0.65302462296307739464   0.46374257973730748095   0.17670065513485988529  59.19553468039021026925  59.69356058756982719160 144.44157782160482383915\n",
      "2.18133   0.91586729818893952704   0.93244927384603548681   0.02829104660288062068   0.04153064806706130430  22.64181697379066093845   5.48835538097493547127 185.67543273790107605237\n",
      "2.05351   0.67930972650246035371   0.72748474119247652503   0.50720508355149052093   1.74491990288165710332   1.48769589574091654072   7.83601782854445971793 208.15683323982082697512\n",
      "2.06444   0.20000004404273413749   1.00000000000000000000   0.00000000000000000000   0.00000000000000000000 100.00000000000000000000 200.00000000000000000000 106.24916052980509562076\n",
      "2.04689   1.00000000000000000000   1.00000000000000000000   0.00000000000390003278   0.00000000000000000000 100.00000000000000000000  75.55497268621888906637   5.00000000000000000000\n",
      "2.08684   0.39624868623397618839   1.00000000000000000000   0.00000000000000000000  27.00000000000000000000  46.20819025963663762013   5.00000000000000000000 300.00000000000000000000\n",
      "2.04458   0.57359029768648828185   1.00000000000000000000   0.30493815268171620136   0.00000000000000000000 100.00000000000000000000   5.00000000000000000000   5.00000000000000000000\n",
      "2.04583   1.00000000000000000000   1.00000000000000000000   0.00000000000000000000   0.00000000000000000000  -1.00000000000000000000 109.57964419608407524720 300.00000000000000000000\n",
      "2.04553   1.00000000000000000000   1.00000000000000000000   0.00000000000000000000   0.00000000000000000000  50.59087624132349247930 200.00000000000000000000 300.00000000000000000000\n",
      "2.19108   0.20000000107546866968   1.00000000000000000000   0.00000000000000000000   0.00000000000000000000  59.53768262723594517638   5.00000000000000000000 190.93859869945592322438\n",
      "2.04553   1.00000000000000000000   1.00000000000000000000   0.00000000064412634231   0.00000000000000000000  -1.00000000000000000000 200.00000000000000000000 218.44802096745920039211\n",
      "2.12346   0.20000000000000001110   0.99999999999998934186   0.00000000000000000000  26.99999999999996092015 100.00000000000000000000 137.60562966745010271552  54.60892532496490048288\n",
      "2.04326   0.67003439645404427871   0.79481738338716145797   0.60104313726359248626  26.49008196233947032283  98.39965859285632632236 199.29567509157607219095  44.20533279619467492694\n",
      "2.03901   0.58135195468278477726   0.98735785991541935580   0.89652135115611397698   0.26756074305631671884  98.86109671664051745665 133.66464374581920537821 106.31443187651606763211\n",
      "2.08599   0.24466511817188313360   0.68100025171925648859   0.64663053221138011573  27.00000000000000000000  -1.00000000000000000000  85.68846162374208574875   6.05485563161749329453\n",
      "2.03855   0.69800175959190280395   0.20000002426714649784   1.00000000000000000000   0.00000000000000000000 100.00000000000000000000 200.00000000000000000000 207.48083878744907337932\n",
      "2.04758   0.47942197385284046618   0.77651772873927593643   0.96664978759982345125  26.71980556113505045346  97.25372177980499088790 143.59486521893086319324   8.82235271996369618819\n"
     ]
    }
   ],
   "source": [
    "colname = ''\n",
    "colname += 'score'.center(7, ' ')\n",
    "for key in LGB_BO.res[0]['params'].keys():\n",
    "    name = key.center(25, ' ')\n",
    "    colname += name\n",
    "print(colname)\n",
    "for idx, item in enumerate(LGB_BO.res):\n",
    "    msg = ''\n",
    "    msg += '{0:7.5f}'.format(item['target'])\n",
    "    for key in item['params'].keys():\n",
    "        val = item['params'][key]\n",
    "        msg += ' {0:24.20f}'.format(val)\n",
    "    print(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
